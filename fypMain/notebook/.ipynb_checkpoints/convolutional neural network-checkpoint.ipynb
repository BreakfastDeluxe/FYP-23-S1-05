{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64a7e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "150d44b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train: cat = 3000 images, dog = 3000 images\n",
    "#Val : cat = 1500 iamges, dog = 1000 images\n",
    "\n",
    "base_dir = r'/Users/brandontan/a_data_truncated'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ce80bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6002 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = ImageDataGenerator(rescale = 1./255,\n",
    "                                shear_range = 0.2,\n",
    "                                zoom_range = 0.2,\n",
    "                                horizontal_flip = True)\n",
    "\n",
    "train_gen = train_data.flow_from_directory(train_dir,\n",
    "                                           target_size = (128, 128),\n",
    "                                           batch_size = 64,\n",
    "                                           class_mode = 'binary')\n",
    "\n",
    "#Val and test only need rescaling\n",
    "val_test_data = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "val_gen = val_test_data.flow_from_directory(val_dir,\n",
    "                                           target_size = (128, 128),\n",
    "                                           batch_size = 64,\n",
    "                                           class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a7c3ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn.add(Conv2D(filters, (kernel size), inputshape))\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(32, (3,3), input_shape = (128, 128, 3)))\n",
    "cnn.add(Activation('relu'))\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "cnn.add(Conv2D(32, (3,3)))\n",
    "cnn.add(Activation('relu'))\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "cnn.add(Conv2D(64, (3,3)))\n",
    "cnn.add(Activation('relu'))\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "#Fully connected layer\n",
    "#Flatten change the dimension to 1d\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128))\n",
    "cnn.add(Activation('relu'))\n",
    "cnn.add(Dense(1))\n",
    "cnn.add(Activation('sigmoid'))\n",
    "\n",
    "cnn.compile(optimizer = 'adam', loss= 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46c4641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping method - prevent overfitting\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', patience = 2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1909619c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "94/94 [==============================] - 95s 980ms/step - loss: 0.7064 - accuracy: 0.5368 - val_loss: 0.6609 - val_accuracy: 0.6015\n",
      "Epoch 2/3\n",
      "94/94 [==============================] - 87s 920ms/step - loss: 0.6335 - accuracy: 0.6391 - val_loss: 0.6081 - val_accuracy: 0.6775\n",
      "Epoch 3/3\n",
      "94/94 [==============================] - 84s 888ms/step - loss: 0.5927 - accuracy: 0.6809 - val_loss: 0.5800 - val_accuracy: 0.6935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1485a42e0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training begins\n",
    "cnn.fit(train_gen, validation_data = val_gen, epochs = 3, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13b93073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "46ef687f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mlmodel/cnn_model.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/mlmodel/cnn_model.joblib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/numpy_pickle.py:552\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    550\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[0;32m--> 552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    553\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mlmodel/cnn_model.joblib'"
     ]
    }
   ],
   "source": [
    "dump(cnn, '/mlmodel/cnn_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff03d11",
   "metadata": {},
   "source": [
    "cnnaaa = joblib.load('/Users/brandontan/Desktop/FYP/num2/FYP-23-S1-05/fypMain/whatisthis/MLmodel/cnn_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046958f4",
   "metadata": {},
   "source": [
    "cnnaaa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1706d35",
   "metadata": {},
   "source": [
    "modell = cnnaaa.predict(val_gen)\n",
    "modell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538a494e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
