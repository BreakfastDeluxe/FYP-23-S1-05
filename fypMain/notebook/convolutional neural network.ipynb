{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64a7e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 21:06:19.706903: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "150d44b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train: cat = 3000 images, dog = 3000 images\n",
    "#Val : cat = 1500 iamges, dog = 1000 images\n",
    "\n",
    "base_dir = r'/Users/brandontan/a_data_truncated'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ce80bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6002 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = ImageDataGenerator(rescale = 1./255,\n",
    "                                shear_range = 0.2,\n",
    "                                zoom_range = 0.2,\n",
    "                                horizontal_flip = True)\n",
    "\n",
    "train_gen = train_data.flow_from_directory(train_dir,\n",
    "                                           target_size = (128, 128),\n",
    "                                           batch_size = 64,\n",
    "                                           class_mode = 'binary')\n",
    "\n",
    "#Val and test only need rescaling\n",
    "val_test_data = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "val_gen = val_test_data.flow_from_directory(val_dir,\n",
    "                                           target_size = (128, 128),\n",
    "                                           batch_size = 64,\n",
    "                                           class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c3ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 21:06:38.205289: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#cnn.add(Conv2D(filters, (kernel size), inputshape))\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(32, (3,3), input_shape = (128, 128, 3)))\n",
    "cnn.add(Activation('relu'))\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "cnn.add(Conv2D(32, (3,3)))\n",
    "cnn.add(Activation('relu'))\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "cnn.add(Conv2D(64, (3,3)))\n",
    "cnn.add(Activation('relu'))\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "#Fully connected layer\n",
    "#Flatten change the dimension to 1d\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128))\n",
    "cnn.add(Activation('relu'))\n",
    "cnn.add(Dense(1))\n",
    "cnn.add(Activation('sigmoid'))\n",
    "\n",
    "cnn.compile(optimizer = 'adam', loss= 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c4641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping method - prevent overfitting\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', patience = 2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1909619c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 76s 783ms/step - loss: 0.6918 - accuracy: 0.5420 - val_loss: 0.6796 - val_accuracy: 0.5840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14524b8b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training begins\n",
    "cnn.fit(train_gen, validation_data = val_gen, epochs = 1, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13b93073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46ef687f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......activation\n",
      ".........vars\n",
      "......activation_1\n",
      ".........vars\n",
      "......activation_2\n",
      ".........vars\n",
      "......activation_3\n",
      ".........vars\n",
      "......activation_4\n",
      ".........vars\n",
      "......conv2d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv2d_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......conv2d_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......max_pooling2d\n",
      ".........vars\n",
      "......max_pooling2d_1\n",
      ".........vars\n",
      "......max_pooling2d_2\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-03-25 21:09:08         4483\n",
      "metadata.json                                  2023-03-25 21:09:08           64\n",
      "variables.h5                                   2023-03-25 21:09:08     19663912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./../mlmodel/cnn_model.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(cnn, './../mlmodel/cnn_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff03d11",
   "metadata": {},
   "source": [
    "cnnaaa = joblib.load('/Users/brandontan/Desktop/FYP/num2/FYP-23-S1-05/fypMain/whatisthis/MLmodel/cnn_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046958f4",
   "metadata": {},
   "source": [
    "cnnaaa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1706d35",
   "metadata": {},
   "source": [
    "modell = cnnaaa.predict(val_gen)\n",
    "modell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538a494e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
